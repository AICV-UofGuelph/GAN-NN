{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/ac5dcd03a40a08a8af7e1a67ade37f28cf88db43/ML/Pytorch/GANs/2.%20DCGAN/train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tfms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os, math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare GAN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, features, device='cpu'):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, features, kernel_size=3, stride=1, padding=1, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features * 2, kernel_size=3, stride=1, padding=1, bias=False, device=device),\n",
    "            nn.InstanceNorm2d(features * 2, affine=True, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(features * 2, features * 4, kernel_size=3, stride=1, padding=1, bias=False, device=device),\n",
    "            nn.InstanceNorm2d(features * 4, affine=True, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(features * 4, 1, kernel_size=3, stride=1, padding=1, device=device), # convert to single channel\n",
    "            nn.AdaptiveAvgPool2d(1),    # pool the matrix into a single value for sigmoid\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 input channels (noise, map, initial path)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, features, device='cpu'):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, features, 3, 1, 1, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features*2, 3, 1, 1, device=device),\n",
    "            nn.InstanceNorm2d(features*2, affine=True, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn. Conv2d(features*2, features, 3, 1, 1, device=device),\n",
    "            nn.InstanceNorm2d(features, affine=True, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn. Conv2d(features, 1, 3, 1, 1, device=device),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "\n",
    "        y = y*255\n",
    "        y = self._round(y)\n",
    "        return y\n",
    "    \n",
    "    def _round(self, mat):\n",
    "        # TODO: cite something? (this function is based off of Thor's code)\n",
    "        mat_hard = torch.round(mat)\n",
    "        mat = (mat_hard - mat.data) + mat\n",
    "\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(coeff, critic, real, fake, device=\"cpu\"):\n",
    "    # sample x_hat from P(x_hat)\n",
    "    rand = torch.randn((real.shape[0], 1, 1, 1), device=device) # generate a random number from 0 to 1 for each matrix in the batch\n",
    "    x_hat = rand*real + (1-rand)*fake\n",
    "\n",
    "    critic_output = critic(x_hat)\n",
    "    grad_ones = torch.ones_like(critic_output, device=device)\n",
    "\n",
    "    gp = torch.autograd.grad(                                   # find magnitude of critic's resulting gradient\n",
    "        inputs = x_hat,\n",
    "        outputs = critic_output,\n",
    "        grad_outputs = grad_ones,\n",
    "        create_graph = True,\n",
    "        retain_graph = True\n",
    "    )[0]\n",
    "\n",
    "    gp = torch.norm(gp, p=2, dim=(1,2,3))    # vector norm of each gradient\n",
    "    gp = (gp - 1)**2\n",
    "    gp = coeff * torch.mean(gp)\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Constants, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testbed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mnist'   # Data at benchmark/{DATASET}/data/\n",
    "RUN_ID = 't1'       # Checkpoints at benchmark/{DATASET}/checkpoints/{RUN_ID}/\n",
    "\n",
    "LOAD = False\n",
    "SAVE = False\n",
    "curr_epoch = 0\n",
    "\n",
    "GEN_PATH = f'./benchmark/{DATASET}/checkpoints/{RUN_ID}/generator/'\n",
    "DISC_PATH = f'./benchmark/{DATASET}/checkpoints/{RUN_ID}/critic/'\n",
    "LOAD_EPOCH = 0  # The epoch checkpoint to load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "NUM_EPOCHS = 10\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "NOISE_SHAPE = (BATCH_SIZE, 1, 0, 0)\n",
    "\n",
    "#Speicific to WGAN\n",
    "CRITIC_ITERATIONS = 5 # how many times the critic loop runs for each generator loop\n",
    "LAMBDA_GP = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data & GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddAffine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    # Assumes input is a 3D matrix (C,H,W)\n",
    "    def forward(self, image):\n",
    "        max = (image.shape[2]-1, image.shape[1]-1)\n",
    "        affine = torch.zeros_like(image[:1,:,:])\n",
    "\n",
    "        # Draw lines between the corners of the affine matrix\n",
    "        x = 0\n",
    "        b1, b2 = (0,max[1])\n",
    "        m1 = max[1] / max[0]\n",
    "        m2 = -max[1] / max[0]\n",
    "        while (x <= max[0]):\n",
    "            y1 = m1*x + b1\n",
    "            y2 = m2*x + b2\n",
    "            y1 = round(y1)\n",
    "            y2 = round(y2)\n",
    "            affine[0,y1,x] = 1\n",
    "            affine[0,y2,x] = 1\n",
    "            x += 1\n",
    "\n",
    "        y = 0\n",
    "        b1, b2 = (0,max[0])\n",
    "        m1 = max[0] / max[1]\n",
    "        m2 = -max[0] / max[1]\n",
    "        while (y <= max[1]):\n",
    "            x1 = m1*y + b1\n",
    "            x2 = m2*y + b2\n",
    "            x1 = round(x1)\n",
    "            x2 = round(x2)\n",
    "            affine[0,y,x1] = 1\n",
    "            affine[0,y,x2] = 1\n",
    "            y += 1\n",
    "\n",
    "        # draw line along the top\n",
    "        x = 0\n",
    "        while (x <= max[0]):\n",
    "            affine[0,0,x] = 1\n",
    "            x += 1\n",
    "        \n",
    "        # Append affine to image along channels axis\n",
    "        out = torch.concat((image, affine), axis=0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundImg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, image):\n",
    "        # TODO: cite something? (this function is based off of Thor's code)\n",
    "        image_hard = torch.round(image)\n",
    "        image = (image_hard - image.data) + image\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tfms.Compose(\n",
    "    [\n",
    "        tfms.ToTensor(),\n",
    "        nn.Sequential(\n",
    "            # RoundImg(),\n",
    "            # AddAffine(),\n",
    "            # tfms.RandomAffine(degrees=180, translate=(0.5,0.5), scale=(0.5,1.5), shear=None)\n",
    "            # AddLabel()\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data & Initialize GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = datasets.MNIST(root='benchmark/datasets/', train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "gen = Generator(FEATURES_GEN, device=device)\n",
    "critic = Discriminator(FEATURES_DISC, device=device)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas = (0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas = (0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    # Load gen\n",
    "    checkpoint = torch.load(f'{GEN_PATH}epoch-{LOAD_EPOCH}.tar')\n",
    "    gen.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt_gen.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    curr_epoch = checkpoint['epoch']\n",
    "    loss_gen = checkpoint['loss']\n",
    "\n",
    "    # Load critic\n",
    "    checkpoint = torch.load(f'{DISC_PATH}epoch-{LOAD_EPOCH}.tar')\n",
    "    critic.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt_critic.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    curr_epoch = checkpoint['epoch']\n",
    "    loss_critic = checkpoint['loss']\n",
    "else:\n",
    "    initialize_weights(gen)\n",
    "    initialize_weights(critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = None\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "# writer_affine = SummaryWriter(f'logs/affine')\n",
    "# writer_labels = SummaryWriter(f'logs/labels')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    curr_epoch += 1\n",
    "    for batch_idx, (imgs, labels) in enumerate(dataloader):\n",
    "        NOISE_SHAPE = (imgs.shape[0], 1, imgs.shape[2], imgs.shape[3])\n",
    "        if fixed_noise == None:\n",
    "            fixed_noise = torch.randn(NOISE_SHAPE, device=device)\n",
    "        # labels = labels[:,None,None,None]\n",
    "        # labels = labels.expand(NOISE_SHAPE).to(device)\n",
    "\n",
    "        real = imgs.to(device)\n",
    "        # real = torch.concat((real, labels), axis=1)\n",
    "\n",
    "        # affine = real[:,1:2,:,:]\n",
    "        noise = torch.randn(NOISE_SHAPE, device=device)\n",
    "        # noise = torch.concat((noise, affine, labels), axis=1)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        # fixed_input = torch.concat((fixed_noise, affine, labels), axis=1)\n",
    "\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(NOISE_SHAPE, device=device)\n",
    "            # noise = torch.concat((noise, affine, labels), axis=1)\n",
    "            fake = gen(noise)\n",
    "            # fake = torch.concat((fake, affine, labels), axis=1)\n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake)\n",
    "            gp = gradient_penalty(LAMBDA_GP, critic, real, fake, device=device) # compute the gradient penalty\n",
    "            loss_critic = (\n",
    "                torch.mean(critic_fake) - torch.mean(critic_real) + gp\n",
    "            )\n",
    "                                                                            #   optim algorithms are for minimizing so take - \n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True) # want to re use the computations for fake for generator\n",
    "            opt_critic.step()\n",
    "\n",
    "        ### Training generator: min E(critic(gen_fake))\n",
    "        output = critic(fake)\n",
    "        loss_gen = -torch.mean(output)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{curr_epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \" +     # TODO: print correct ending epoch based on initial (loaded) epoch num\n",
    "                  f\"Loss D: {loss_critic:.4f}, Lambda GP: {LAMBDA_GP*gp:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # fake = gen(fixed_input)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    real[:BATCH_SIZE,:,:,:], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:BATCH_SIZE,:,:,:], normalize=True\n",
    "                )\n",
    "                # img_grid_labels = torchvision.utils.make_grid(\n",
    "                #     real[:BATCH_SIZE,:,:,:], normalize=True\n",
    "                # )\n",
    "                # img_grid_affine = torchvision.utils.make_grid(\n",
    "                #     real[:BATCH_SIZE,:,:,:], normalize=True\n",
    "                # )\n",
    "\n",
    "                writer_real.add_image(\"Digits\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Digits\", img_grid_fake, global_step=step)\n",
    "                # writer_labels.add_image('Info', img_grid_labels, global_step=step)\n",
    "                # writer_labels.add_image('Info', img_grid_labels, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    # save generator checkpoint\n",
    "    if SAVE:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': gen.state_dict(),\n",
    "                    'optimizer_state_dict': opt_gen.state_dict(),\n",
    "                    'loss': loss_gen,\n",
    "        }, f\"{GEN_PATH}epoch-{epoch}.tar\")\n",
    "\n",
    "        # save critic checkpoint\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': critic.state_dict(),\n",
    "                    'optimizer_state_dict': opt_critic.state_dict(),\n",
    "                    'loss': loss_critic,\n",
    "        }, f\"{DISC_PATH}epoch-{epoch}.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

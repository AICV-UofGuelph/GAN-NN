{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tfms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, math\n",
    "import random\n",
    "import numpy as np\n",
    "from create_paths import smoothen_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 input channels (noise, map, initial path)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, features, device='cpu'):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, features, 5, 1, 2, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features*2, 5, 1, 2, device=device),\n",
    "            nn.InstanceNorm2d(features*2, affine=True, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn. Conv2d(features*2, features, 5, 1, 2, device=device),\n",
    "            nn.InstanceNorm2d(features, affine=True, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn. Conv2d(features, 1, 5, 1, 2, device=device),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "\n",
    "        # y = F.adaptive_max_pool2d(y, output_size=map_shape)\n",
    "\n",
    "        y = self._round(y)\n",
    "        return y\n",
    "    \n",
    "    def _round(self, mat):\n",
    "        # TODO: cite something? (this function is based off of Thor's code)\n",
    "        mat_hard = torch.round(mat)\n",
    "        mat = (mat_hard - mat.data) + mat\n",
    "\n",
    "        return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to override __init__, __len__, __getitem__\n",
    "# as per datasets requirement\n",
    "class PathsDataset(torch.utils.data.Dataset):\n",
    "    # init the dataset, shape = L x W\n",
    "    def __init__(self, path_dir, map_file, transform=None, shape = (100,100), device='cpu'):\n",
    "        self.device = device\n",
    "        self.paths = [] # create a list to hold all paths read from file\n",
    "        self.map = np.loadtxt(map_file, skiprows=2).reshape(shape)\n",
    "        self.map = self.map[np.newaxis, :, :]\n",
    "        for filename in os.listdir(path_dir):\n",
    "            with open(os.path.join(path_dir, filename), 'r') as f: # open in readonly mode\n",
    "                self.flat_path = np.loadtxt(f) # load in the flat path from file\n",
    "                self.path = np.asarray(self.flat_path, dtype=int).reshape(len(self.flat_path)//2,2) #unflatten the path from the file\n",
    "\n",
    "                self.path_matrix = self.convert_path(shape, self.path)\n",
    "                \n",
    "                self.paths.append(self.path_matrix) # add the path to paths list\n",
    "        self.transform = transform\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def convert_path(self, map_dim, path):\n",
    "        path_mat = np.zeros(map_dim, dtype=float)\n",
    "\n",
    "        # Make the path continuous\n",
    "        for i in range(path.shape[0] - 1):\n",
    "            x = path[i,0]\n",
    "            x1 = path[i,0]\n",
    "            x2 = path[i+1,0]\n",
    "\n",
    "            y = path[i,1]\n",
    "            y1 = path[i,1]\n",
    "            y2 = path[i+1,1]\n",
    "\n",
    "            if (x1 < x2):\n",
    "                x_dir = 1\n",
    "            else:\n",
    "                x_dir = -1\n",
    "\n",
    "            if (y1 < y2):\n",
    "                y_dir = 1\n",
    "            else:\n",
    "                y_dir = -1\n",
    "\n",
    "            # Determine y from x\n",
    "            if x2-x1 != 0:\n",
    "                m = (y2-y1)/(x2-x1)\n",
    "                while x != x2:\n",
    "                    y = round(m*(x-x1) + y1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    x += x_dir\n",
    "            else:\n",
    "                while x != x2:\n",
    "                    path_mat[y1,x] = 1\n",
    "                    x += x_dir\n",
    "\n",
    "\n",
    "            x = path[i,0]\n",
    "            x1 = path[i,0]\n",
    "            x2 = path[i+1,0]\n",
    "\n",
    "            y = path[i,1]\n",
    "            y1 = path[i,1]\n",
    "            y2 = path[i+1,1]\n",
    "\n",
    "            # Determine x from y\n",
    "            if y2-y1 != 0:\n",
    "                m = (x2-x1)/(y2-y1)\n",
    "                while y != y2:\n",
    "                    x = round(m*(y-y1) + x1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    y += y_dir\n",
    "            else:\n",
    "                while y != y2:\n",
    "                    path_mat[y,x1] = 1\n",
    "                    y += y_dir\n",
    "            \n",
    "        path_mat[path[path.shape[0]-1,1], path[path.shape[0]-1,0]] = 1     # Include the last point in the path\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Add Initial Path onto the loaded path matrix\n",
    "        initial_path = np.zeros_like(path_mat)\n",
    "\n",
    "        # Create Straight line between start/end points\n",
    "        x1 = path[0,0]\n",
    "        y1 = path[0,1]\n",
    "        x2 = path[path.shape[0]-1,0]\n",
    "        y2 = path[path.shape[0]-1,1]\n",
    "\n",
    "        x = x1\n",
    "        y = y1\n",
    "\n",
    "        if (x1 < x2):\n",
    "            x_dir = 1\n",
    "        else:\n",
    "            x_dir = -1\n",
    "\n",
    "        if (y1 < y2):\n",
    "            y_dir = 1\n",
    "        else:\n",
    "            y_dir = -1\n",
    "\n",
    "        # Determine y from x\n",
    "        if x2-x1 != 0:\n",
    "            m = (y2-y1)/(x2-x1)\n",
    "            while x != x2:\n",
    "                y = round(m*(x-x1) + y1)\n",
    "                initial_path[y,x] = 1\n",
    "                x += x_dir\n",
    "        else:\n",
    "            while x != x2:\n",
    "                initial_path[y1,x] = 1\n",
    "                x += x_dir\n",
    "\n",
    "        x = x1\n",
    "        y = y1\n",
    "        # Determine x from y\n",
    "        if y2-y1 != 0:\n",
    "            m = (x2-x1)/(y2-y1)\n",
    "            while y != y2:\n",
    "                x = round(m*(y-y1) + x1)\n",
    "                initial_path[y,x] = 1\n",
    "                y += y_dir\n",
    "        else:\n",
    "            while y != y2:\n",
    "                initial_path[y,x1] = 1\n",
    "                y += y_dir\n",
    "\n",
    "        path_mat = np.stack((path_mat, initial_path))\n",
    "\n",
    "        return path_mat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.float32(self.paths[idx])\n",
    "        x = torch.Tensor(x).to(self.device)\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "        #return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tfms.Compose(\n",
    "    [\n",
    "        # tfms.ToTensor(),\n",
    "        # tfms.Normalize(\n",
    "        #     [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        # ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "MAP_NAME = 'map_64x64'\n",
    "MAP_SHAPE = (64,64)\n",
    "# MAP_NAME = '8x12_map'\n",
    "# MAP_SHAPE = (163,243)\n",
    "START = (10,10)\n",
    "GOAL = (55,55)\n",
    "\n",
    "NUM_EXAMPLES = 5\n",
    "\n",
    "GEN_PATH = './checkpoints/wgan_gp/generator_test/epoch-0.pt'\n",
    "LOAD_EPOCH = 0  # The epoch checkpoint to load\n",
    "\n",
    "# # Hyperparameters etc.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = 50\n",
    "\n",
    "NOISE_SHAPE = (INPUT_SIZE, 1, MAP_SHAPE[0], MAP_SHAPE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open map file:\n",
    "map = np.loadtxt(f\"./env/{MAP_NAME}/{MAP_NAME}.txt\", skiprows=2).reshape(MAP_SHAPE)\n",
    "map = map[np.newaxis,np.newaxis,:,:]\n",
    "map = np.repeat(map, INPUT_SIZE, axis=0)\n",
    "map = torch.Tensor(map).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.load(GEN_PATH)\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PathsDataset(path_dir = f\"./env/{MAP_NAME}/paths/good_paths\", map_file = f\"./env/{MAP_NAME}/{MAP_NAME}.txt\", shape = MAP_SHAPE, transform=transforms, device=device)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=INPUT_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for batch_idx, real in enumerate(dataloader_test):\n",
    "\n",
    "    if count == NUM_EXAMPLES:\n",
    "        break\n",
    "\n",
    "    initial_path = real[:,1:2,:,:]\n",
    "    rrt_path = real[:,0:1,:,:]\n",
    "    noise = torch.randn(NOISE_SHAPE, device=device)\n",
    "    noise = torch.concat((noise, initial_path, map), axis=1)\n",
    "    \n",
    "    result = gen(noise).cpu().detach().numpy()[0][0].tolist()\n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "\n",
    "\n",
    "    # display RRT* path:\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.imshow(rrt_path[0][0].cpu())\n",
    "    plt.title(\"RRT* Path\")\n",
    "\n",
    "    # display the path the generator created:\n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.imshow(result)\n",
    "    plt.title(\"Generated Path\")\n",
    "\n",
    "    # create smoothened path:\n",
    "    smooth_paths = smoothen_paths([result], START, GOAL, figsize=(5,5), display=False)[0]\n",
    "\n",
    "    # display smoothened path and obstacle map:\n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.imshow(map.cpu()[0][0])\n",
    "    plt.plot(smooth_paths[:,1], smooth_paths[:,0])\n",
    "    plt.scatter(START[1], START[0], c=\"g\", zorder=5)\n",
    "    plt.scatter(GOAL[1], GOAL[0], c=\"r\", zorder=5)\n",
    "    plt.title(\"Smoothened Path on Map\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    count += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

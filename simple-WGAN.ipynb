{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/ac5dcd03a40a08a8af7e1a67ade37f28cf88db43/ML/Pytorch/GANs/2.%20DCGAN/train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tfms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, features, device='cpu'):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, features, kernel_size=4, stride=2, padding=1, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features * 2, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 2, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(features * 2, features * 4, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 4, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(features * 4, features * 8, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 8, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, 1, kernel_size=4, stride=2, padding=0, device=device), # convert to single channel\n",
    "            nn.AdaptiveAvgPool2d(1),    # pool the matrix into a single value for sigmoid\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "        y = self.block5(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_channels, features, device='cpu'):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_channels, features * 16, kernel_size=4, stride=1, padding=0, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 16, features * 8, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 8, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 8, features * 4, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 4, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 4, features * 2, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 2, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 2, 1, kernel_size=4, stride=2, padding=1, device=device),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, map_shape):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "        y = self.block5(y)\n",
    "\n",
    "        y = F.adaptive_avg_pool2d(y, map_shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to override __init__, __len__, __getitem__\n",
    "# as per datasets requirement\n",
    "class PathsDataset(torch.utils.data.Dataset):\n",
    "    # init the dataset, shape = L x W\n",
    "    def __init__(self, path, transform=None, shape = (100,100)):\n",
    "        self.paths = [] # create a list to hold all paths read from file\n",
    "        for filename in os.listdir(path):\n",
    "            with open(os.path.join(path, filename), 'r') as f: # open in readonly mode\n",
    "                self.flat_path = np.loadtxt(f) # load in the flat path from file\n",
    "                self.path = np.asarray(self.flat_path, dtype=int).reshape(len(self.flat_path)//2,2) #unflatten the path from the file\n",
    "\n",
    "                self.path_matrix = self.convert_path(shape, self.path)\n",
    "                \n",
    "                self.paths.append(self.path_matrix) # add the path to paths list\n",
    "        self.transform = transform\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def convert_path(self, map_dim, path):\n",
    "        path_mat = np.zeros(map_dim, dtype=float)\n",
    "\n",
    "        RATIO = 400/128\n",
    "\n",
    "        # Make the path continuous\n",
    "        for i in range(path.shape[0] - 1):\n",
    "            x = math.floor(path[i,0] / RATIO)\n",
    "            x1 = math.floor(path[i,0] / RATIO)\n",
    "            x2 = math.floor(path[i+1,0] / RATIO)\n",
    "\n",
    "            y = math.floor(path[i,1] / RATIO)\n",
    "            y1 = math.floor(path[i,1] / RATIO)\n",
    "            y2 = math.floor(path[i+1,1] / RATIO)\n",
    "\n",
    "            if (x1 < x2):\n",
    "                x_dir = 1\n",
    "            else:\n",
    "                x_dir = -1\n",
    "\n",
    "            if (y1 < y2):\n",
    "                y_dir = 1\n",
    "            else:\n",
    "                y_dir = -1\n",
    "\n",
    "            # Determine y from x\n",
    "            if x2-x1 != 0:\n",
    "                m = (y2-y1)/(x2-x1)\n",
    "                while x != x2:\n",
    "                    y = round(m*(x-x1) + y1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    x += x_dir\n",
    "            else:\n",
    "                while x != x2:\n",
    "                    path_mat[y1,x] = 1\n",
    "                    x += x_dir\n",
    "\n",
    "\n",
    "            x = math.floor(path[i,0] // RATIO)\n",
    "            x1 = math.floor(path[i,0] // RATIO)\n",
    "            x2 = math.floor(path[i+1,0] // RATIO)\n",
    "\n",
    "            y = math.floor(path[i,1] // RATIO)\n",
    "            y1 = math.floor(path[i,1] // RATIO)\n",
    "            y2 = math.floor(path[i+1,1] // RATIO)\n",
    "\n",
    "            # Determine x from y\n",
    "            if y2-y1 != 0:\n",
    "                m = (x2-x1)/(y2-y1)\n",
    "                while y != y2:\n",
    "                    x = round(m*(y-y1) + x1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    y += y_dir\n",
    "            else:\n",
    "                while y != y2:\n",
    "                    path_mat[y,x1] = 1\n",
    "                    y += y_dir\n",
    "            \n",
    "        path_mat[path[path.shape[0]-1,1], path[path.shape[0]-1,0]] = 1     # Include the last point in the path\n",
    "\n",
    "        return path_mat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.float32(self.paths[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x).cuda()\n",
    "            \n",
    "\n",
    "        return x\n",
    "\n",
    "        #return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_dims(map_dims):\n",
    "    # For each convtranspose layer:\n",
    "    # dim = round(math.ceil((dim + (2*padding) - kernel_size) / stride)) + 1\n",
    "    # The output will need to be trimmed down to the desired size (This may hurt generalizability)\n",
    "    noise_shape = []\n",
    "    for i in range(len(map_dims)):\n",
    "        shape = map_dims[i]\n",
    "\n",
    "        shape = ((shape + (2*1) - 4) // 2) + 1  # Layer 5\n",
    "        shape = ((shape + (2*1) - 4) // 2) + 1  # Layer 4\n",
    "        shape = ((shape + (2*1) - 4) // 2) + 1  # Layer 3\n",
    "        shape = ((shape + (2*1) - 4) // 2) + 1  # Layer 2\n",
    "        shape = ((shape + (2*0) - 4) // 2) + 1  # Layer 1\n",
    "\n",
    "        # shape += 1  # Trim the generated paths down later\n",
    "        noise_shape.append(shape)\n",
    "\n",
    "    noise_shape = tuple(noise_shape)\n",
    "    return noise_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters etc.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 5e-4\n",
    "BATCH_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 20\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "MAP_SHAPE = (128,128)\n",
    "noise_shape = noise_dims(MAP_SHAPE)\n",
    "\n",
    "#Speicific to WGAN\n",
    "WEIGHT_CLIP = 0.01 # C param from WGAN paper\n",
    "CRITIC_ITERATIONS = 5 # how many times the critic loop runs for each generator loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tfms.Compose(\n",
    "    [\n",
    "        tfms.ToTensor(),\n",
    "        tfms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment mnist above and uncomment below if train on CelebA\n",
    "# dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\n",
    "\n",
    "dataset = PathsDataset(path = \"./env/map_20x20/paths/\", shape = (400,400), transform=transforms)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "gen = Generator(NOISE_DIM, FEATURES_GEN, device=device)\n",
    "critic = Discriminator(FEATURES_DISC, device=device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
    "opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn((BATCH_SIZE, NOISE_DIM, noise_shape[0], noise_shape[1]), device=device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    # for batch_idx, (real, _) in enumerate(dataloader):\n",
    "    for batch_idx, real in enumerate(dataloader):\n",
    "        noise = torch.randn((BATCH_SIZE, NOISE_DIM, noise_shape[0], noise_shape[1]), device=device)\n",
    "        fake = gen(noise, MAP_SHAPE)\n",
    "\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn((BATCH_SIZE, NOISE_DIM, noise_shape[0], noise_shape[1]), device=device)\n",
    "            fake = gen(noise, MAP_SHAPE)\n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) #   want to maximize (according to paper) but \n",
    "                                                                            #   optim algorithms are for minimizing so take - \n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True) # want to re use the computations for fake for generator\n",
    "            opt_critic.step()\n",
    "\n",
    "            for p in critic.parameters():\n",
    "                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n",
    "\n",
    "        ### Training generator: min E(critic(gen_fake))\n",
    "        output = critic(fake)\n",
    "        loss_gen = -torch.mean(output)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()        \n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise, MAP_SHAPE)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    real[:BATCH_SIZE], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:BATCH_SIZE], normalize=True\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn((BATCH_SIZE, NOISE_DIM, noise_shape[0], noise_shape[1]), device=device)\n",
    "fake = gen(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fake.cpu().detach().numpy()[7][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/ac5dcd03a40a08a8af7e1a67ade37f28cf88db43/ML/Pytorch/GANs/2.%20DCGAN/train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tfms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import os, math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, features, device='cpu'):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, features, kernel_size=4, stride=2, padding=1, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features * 2, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.InstanceNorm2d(features * 2, affine=True, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(features * 2, features * 4, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.InstanceNorm2d(features * 4, affine=True, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(features * 4, features * 8, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.InstanceNorm2d(features * 8, affine=True, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, 1, kernel_size=4, stride=2, padding=0, device=device), # convert to single channel\n",
    "            nn.AdaptiveAvgPool2d(1),    # pool the matrix into a single value for sigmoid\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "        y = self.block5(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 input channels (noise, map, initial path)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, features, device='cpu'):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, features, 5, 1, 2, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features*2, 5, 1, 2, device=device),\n",
    "            nn.InstanceNorm2d(features*2, affine=True, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn. Conv2d(features*2, features, 5, 1, 2, device=device),\n",
    "            nn.InstanceNorm2d(features, affine=True, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn. Conv2d(features, 1, 5, 1, 2, device=device),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "\n",
    "        # y = F.adaptive_max_pool2d(y, output_size=map_shape)\n",
    "\n",
    "        y = self._round(y)\n",
    "        return y\n",
    "    \n",
    "    def _round(self, mat):\n",
    "        # TODO: cite something? (this function is based off of Thor's code)\n",
    "        mat_hard = torch.round(mat)\n",
    "        mat = (mat_hard - mat.data) + mat\n",
    "\n",
    "        return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find x_hat of real/generated paths, then append map and direct path onto x_hat (attempt at avoiding skewed map/direct path values due to floating-point error in epsilon)\n",
    "def gradient_penalty(coeff, critic, real, fake, device=\"cpu\"):\n",
    "    # sample x_hat from P(x_hat)\n",
    "    rand = torch.randn((real.shape[0], 1, 1, 1), device=device) # generate a random number from 0 to 1 for each matrix in the batch\n",
    "    x_hat = rand*real + (1-rand)*fake\n",
    "\n",
    "    critic_output = critic(x_hat)\n",
    "    grad_ones = torch.ones_like(critic_output, device=device)\n",
    "\n",
    "    gp = torch.autograd.grad(                                   # find magnitude of critic's resulting gradient\n",
    "        inputs = x_hat,\n",
    "        outputs = critic_output,\n",
    "        grad_outputs = grad_ones,\n",
    "        create_graph = True,\n",
    "        retain_graph = True\n",
    "    )[0]\n",
    "\n",
    "    gp = torch.norm(gp, p=2, dim=(1,2,3))    # vector norm of each gradient\n",
    "    gp = (gp - 1)**2\n",
    "    gp = coeff * torch.mean(gp)\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to override __init__, __len__, __getitem__\n",
    "# as per datasets requirement\n",
    "class PathsDataset(torch.utils.data.Dataset):\n",
    "    # init the dataset, shape = L x W\n",
    "    def __init__(self, path_dir, map_file, transform=None, shape = (100,100), device='cpu'):\n",
    "        self.device = device\n",
    "        self.paths = [] # create a list to hold all paths read from file\n",
    "        self.map = np.loadtxt(map_file, skiprows=2).reshape(shape)\n",
    "        self.map = self.map[np.newaxis, :, :]\n",
    "        for filename in os.listdir(path_dir):\n",
    "            with open(os.path.join(path_dir, filename), 'r') as f: # open in readonly mode\n",
    "                self.flat_path = np.loadtxt(f) # load in the flat path from file\n",
    "                self.path = np.asarray(self.flat_path, dtype=int).reshape(len(self.flat_path)//2,2) #unflatten the path from the file\n",
    "\n",
    "                self.path_matrix = self.convert_path(shape, self.path)\n",
    "                \n",
    "                self.paths.append(self.path_matrix) # add the path to paths list\n",
    "        self.transform = transform\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def convert_path(self, map_dim, path):\n",
    "        path_mat = np.zeros(map_dim, dtype=float)\n",
    "\n",
    "        # Make the path continuous\n",
    "        for i in range(path.shape[0] - 1):\n",
    "            x = path[i,0]\n",
    "            x1 = path[i,0]\n",
    "            x2 = path[i+1,0]\n",
    "\n",
    "            y = path[i,1]\n",
    "            y1 = path[i,1]\n",
    "            y2 = path[i+1,1]\n",
    "\n",
    "            if (x1 < x2):\n",
    "                x_dir = 1\n",
    "            else:\n",
    "                x_dir = -1\n",
    "\n",
    "            if (y1 < y2):\n",
    "                y_dir = 1\n",
    "            else:\n",
    "                y_dir = -1\n",
    "\n",
    "            # Determine y from x\n",
    "            if x2-x1 != 0:\n",
    "                m = (y2-y1)/(x2-x1)\n",
    "                while x != x2:\n",
    "                    y = round(m*(x-x1) + y1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    x += x_dir\n",
    "            else:\n",
    "                while x != x2:\n",
    "                    path_mat[y1,x] = 1\n",
    "                    x += x_dir\n",
    "\n",
    "\n",
    "            x = path[i,0]\n",
    "            x1 = path[i,0]\n",
    "            x2 = path[i+1,0]\n",
    "\n",
    "            y = path[i,1]\n",
    "            y1 = path[i,1]\n",
    "            y2 = path[i+1,1]\n",
    "\n",
    "            # Determine x from y\n",
    "            if y2-y1 != 0:\n",
    "                m = (x2-x1)/(y2-y1)\n",
    "                while y != y2:\n",
    "                    x = round(m*(y-y1) + x1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    y += y_dir\n",
    "            else:\n",
    "                while y != y2:\n",
    "                    path_mat[y,x1] = 1\n",
    "                    y += y_dir\n",
    "            \n",
    "        path_mat[path[path.shape[0]-1,1], path[path.shape[0]-1,0]] = 1     # Include the last point in the path\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Add Initial Path onto the loaded path matrix\n",
    "        initial_path = np.zeros_like(path_mat)\n",
    "\n",
    "        # Create Straight line between start/end points\n",
    "        x1 = path[0,0]\n",
    "        y1 = path[0,1]\n",
    "        x2 = path[path.shape[0]-1,0]\n",
    "        y2 = path[path.shape[0]-1,1]\n",
    "\n",
    "        x = x1\n",
    "        y = y1\n",
    "\n",
    "        if (x1 < x2):\n",
    "            x_dir = 1\n",
    "        else:\n",
    "            x_dir = -1\n",
    "\n",
    "        if (y1 < y2):\n",
    "            y_dir = 1\n",
    "        else:\n",
    "            y_dir = -1\n",
    "\n",
    "        # Determine y from x\n",
    "        if x2-x1 != 0:\n",
    "            m = (y2-y1)/(x2-x1)\n",
    "            while x != x2:\n",
    "                y = round(m*(x-x1) + y1)\n",
    "                initial_path[y,x] = 1\n",
    "                x += x_dir\n",
    "        else:\n",
    "            while x != x2:\n",
    "                initial_path[y1,x] = 1\n",
    "                x += x_dir\n",
    "\n",
    "        x = x1\n",
    "        y = y1\n",
    "        # Determine x from y\n",
    "        if y2-y1 != 0:\n",
    "            m = (x2-x1)/(y2-y1)\n",
    "            while y != y2:\n",
    "                x = round(m*(y-y1) + x1)\n",
    "                initial_path[y,x] = 1\n",
    "                y += y_dir\n",
    "        else:\n",
    "            while y != y2:\n",
    "                initial_path[y,x1] = 1\n",
    "                y += y_dir\n",
    "\n",
    "        # initial_path[y1,x1] = 1     # Include the first point in the path\n",
    "        # initial_path[y2,x2] = 1     # Include the last point in the path\n",
    "\n",
    "        # slope = -0.25\n",
    "\n",
    "        # for x in range(0, len(initial_path)):\n",
    "        #     for y in range(0, len(initial_path[x])):\n",
    "        #         dis_start = math.sqrt((x-x1)**2 + (y-y1)**2)\n",
    "        #         dis_goal = math.sqrt((x-x2)**2 + (y-y2)**2)\n",
    "        #         dis = dis_start if dis_start < dis_goal else dis_goal\n",
    "\n",
    "        #         # height = slope*dis + 1\n",
    "        #         height = slope*dis\n",
    "\n",
    "        #         # if height < 0:\n",
    "        #         if height > 1:\n",
    "        #             # initial_path[y][x] = 0\n",
    "        #             initial_path[y][x] = 1\n",
    "        #         else:\n",
    "        #             initial_path[y][x] = height\n",
    "\n",
    "        # plt.imshow(initial_path)\n",
    "        # plt.show()\n",
    "\n",
    "        path_mat = np.stack((path_mat, initial_path))\n",
    "\n",
    "        return path_mat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.float32(self.paths[idx])\n",
    "        x = torch.Tensor(x).to(self.device)\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "        #return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "MAP_NAME = 'map_64x64'\n",
    "MAP_SHAPE = (64,64)\n",
    "# MAP_NAME = '8x12_map'\n",
    "# MAP_SHAPE = (163,243)\n",
    "\n",
    "LOAD = False\n",
    "SAVE = True\n",
    "GEN_PATH = './checkpoints/wgan_gp/generator/'\n",
    "DISC_PATH = './checkpoints/wgan_gp/critic/'\n",
    "LOAD_EPOCH = 0  # The epoch checkpoint to load\n",
    "\n",
    "# # Hyperparameters etc.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FEATURES_GEN = 64\n",
    "FEATURES_DISC = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "NOISE_SHAPE = (BATCH_SIZE, 1, MAP_SHAPE[0], MAP_SHAPE[1])\n",
    "\n",
    "#Speicific to WGAN\n",
    "CRITIC_ITERATIONS = 5 # how many times the critic loop runs for each generator loop\n",
    "LAMBDA_GP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tfms.Compose(\n",
    "    [\n",
    "        # tfms.ToTensor(),\n",
    "        # tfms.Normalize(\n",
    "        #     [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        # ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = np.loadtxt(f\"./env/{MAP_NAME}/{MAP_NAME}.txt\", skiprows=2).reshape(MAP_SHAPE)\n",
    "map = map[np.newaxis,np.newaxis,:,:]\n",
    "map = np.repeat(map, BATCH_SIZE, axis=0)\n",
    "map = torch.Tensor(map).to(device)\n",
    "\n",
    "dataset = PathsDataset(path_dir = f\"./env/{MAP_NAME}/paths/random_paths/\", map_file = f\"./env/{MAP_NAME}/{MAP_NAME}.txt\", shape = MAP_SHAPE, transform=transforms, device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_dataset = PathsDataset(path_dir = f\"./env/{MAP_NAME}/paths/training\", map_file = f\"./env/{MAP_NAME}/{MAP_NAME}.txt\", shape = MAP_SHAPE, transform=transforms, device=device)\n",
    "# test_dataset = PathsDataset(path_dir = f\"./env/{MAP_NAME}/paths/testing\", map_file = f\"./env/{MAP_NAME}/{MAP_NAME}.txt\", shape = MAP_SHAPE, transform=transforms, device=device)\n",
    "\n",
    "# dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "# dataloader_test = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_epoch = 0\n",
    "\n",
    "gen = Generator(FEATURES_GEN, device=device)\n",
    "critic = Discriminator(FEATURES_DISC, device=device)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas = (0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas = (0.0, 0.9))\n",
    "\n",
    "if LOAD:\n",
    "    # Load gen\n",
    "    checkpoint = torch.load(f'{GEN_PATH}epoch-{LOAD_EPOCH}.tar')\n",
    "    gen.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt_gen.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    curr_epoch = checkpoint['epoch']\n",
    "    loss_gen = checkpoint['loss']\n",
    "\n",
    "    # Load critic\n",
    "    checkpoint = torch.load(f'{DISC_PATH}epoch-{LOAD_EPOCH}.tar')\n",
    "    critic.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt_critic.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    curr_epoch = checkpoint['epoch']\n",
    "    loss_critic = checkpoint['loss']\n",
    "else:\n",
    "    initialize_weights(gen)\n",
    "    initialize_weights(critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(NOISE_SHAPE, device=device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_overlay = SummaryWriter(f\"logs/fake_overlay\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP Cell, please ignore\n",
    "# n = CRITIC_ITERATIONS\n",
    "# m = BATCH_SIZE\n",
    "# LAMBDA = LAMBDA_GP\n",
    "# # z = generator input\n",
    "# # gp = gradient penalty\n",
    "# # w = optimization amounts for critic?\n",
    "# # theta = optimization amounts for gen?\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     curr_epoch += 1\n",
    "#     for batch_idx, real in enumerate(dataloader):                   # for each batch in the set\n",
    "#         for t in range(n):                                              # For specified number of critic iterations (t is in [0,n)):\n",
    "#             for i in range(m):                                              # For each item in the batch (i is in [0,m)):\n",
    "#                 real_item = real[i]                                             # Get an item from the real dataset\n",
    "\n",
    "#                 z = torch.randn(NOISE_SHAPE, device=device)                     # create the generator's input\n",
    "#                 z = torch.concat((z, initial_path, map), axis=1)\n",
    "#                 fake = gen(z)                                                   # fake = generator output\n",
    "                \n",
    "#                 rand = random.random()                                          # generate a random number r from 0 to 1\n",
    "#                 x_hat = rand*critic(real_item) - (1-rand)*critic(fake)          # x_hat = n*critic(real) - (1-n)*critic(fake)\n",
    "\n",
    "#                 gp = gradient_penalty(LAMBDA, real_item, fake, device=device)   # Get GP\n",
    "#                 loss_critic[i] = critic(real_item)-critic(fake) + LAMBDA*gp     # loss[i] = critic(real)-critic(fake) + lambda*GP\n",
    "            \n",
    "#                                                                             # w = Adam(gradient of {(sum of losses)/m} with respect to w, w, alpha, beta1, beta2)\n",
    "        \n",
    "#         for i in range(m):                                              # Create m inputs for the generator\n",
    "#             z[i] = torch.randn(NOISE_SHAPE, device=device)\n",
    "#             z = torch.concat((z, initial_path, map), axis=1)\n",
    "#         # theta = Adam(gradient of {(sum of -critic(generator(input)) for all m inputs)/m} with respect to theta, theta, alpha, beta1, beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    curr_epoch += 1\n",
    "    for batch_idx, real in enumerate(dataloader):\n",
    "        real = real.to(device)\n",
    "        real = torch.concat((real, map), axis=1)\n",
    "\n",
    "        initial_path = real[:,1:2,:,:]\n",
    "        noise = torch.randn(NOISE_SHAPE, device=device)\n",
    "        noise = torch.concat((noise, initial_path, map), axis=1)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        fixed_input = torch.concat((fixed_noise, initial_path, map), axis=1)\n",
    "\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(NOISE_SHAPE, device=device)\n",
    "            noise = torch.concat((noise, initial_path, map), axis=1)\n",
    "            fake = gen(noise)\n",
    "            fake = torch.concat((fake, initial_path, map), axis=1)\n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake)\n",
    "            gp = gradient_penalty(LAMBDA_GP, critic, real, fake, device=device) # compute the gradient penalty\n",
    "            loss_critic = (\n",
    "                torch.mean(critic_fake) - torch.mean(critic_real) + gp\n",
    "            )\n",
    "                                                                            #   optim algorithms are for minimizing so take - \n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True) # want to re use the computations for fake for generator\n",
    "            opt_critic.step()\n",
    "\n",
    "        ### Training generator: min E(critic(gen_fake))\n",
    "        output = critic(fake)\n",
    "        loss_gen = -torch.mean(output)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()        \n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{curr_epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \" +     # TODO: print correct ending epoch based on initial (loaded) epoch num\n",
    "                  f\"Loss D: {loss_critic:.4f}, Lambda GP: {LAMBDA_GP*gp:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_input)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    real[:BATCH_SIZE], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:BATCH_SIZE], normalize=True\n",
    "                )\n",
    "\n",
    "                fake = torch.concat((fake, initial_path, map), axis=1)\n",
    "                img_grid_fake_overlay = torchvision.utils.make_grid(\n",
    "                    fake[:BATCH_SIZE], normalize=True\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "                writer_overlay.add_image(\"Fake\", img_grid_fake_overlay, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    # save generator checkpoint\n",
    "    if SAVE:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': gen.state_dict(),\n",
    "                    'optimizer_state_dict': opt_gen.state_dict(),\n",
    "                    'loss': loss_gen,\n",
    "        }, f\"{GEN_PATH}epoch-{epoch}.tar\")\n",
    "\n",
    "        # save critic checkpoint\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': critic.state_dict(),\n",
    "                    'optimizer_state_dict': opt_critic.state_dict(),\n",
    "                    'loss': loss_critic,\n",
    "        }, f\"{DISC_PATH}epoch-{epoch}.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

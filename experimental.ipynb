{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/ac5dcd03a40a08a8af7e1a67ade37f28cf88db43/ML/Pytorch/GANs/2.%20DCGAN/train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tfms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os, math\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import skfmm\n",
    "\n",
    "import GAN as GAN\n",
    "from GAN import Generator\n",
    "from GAN import Critic\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Weights and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORD_METRICS = True\n",
    "\n",
    "# Inputs\n",
    "INPUT_DIR = 'inputs'\n",
    "DATASET = 'many_maps_1'\n",
    "SUBSET = 'train'\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "\n",
    "# Structure\n",
    "NUM_LAYERS_CRIT = 5\n",
    "KERNEL_CRIT = [4,4,4,4,4]\n",
    "STRIDE_CRIT = [2,2,2,2,1]\n",
    "PAD_CRIT = [1,1,1,1,0]\n",
    "FEATURES_CRIT = [3,64,128,256,512]\n",
    "\n",
    "NUM_LAYERS_GEN = 10\n",
    "KERNEL_GEN = [4,4,4,4,4,4,4,4,4,4]\n",
    "STRIDE_GEN = [2,2,2,2,1,1,2,2,2,2]\n",
    "PAD_GEN = [1,1,1,1,0,0,1,1,1,1]\n",
    "FEATURES_GEN = [2,64,128,256,512,1024,512,256,128,64]\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "LR_CRIT = 1e-4\n",
    "LR_GEN = 1e-4\n",
    "CRIT_ITERATIONS = 5\n",
    "LAMBDA = 50\n",
    "\n",
    "\n",
    "# Internal Data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAP_SHAPE = (64,64)\n",
    "NOISE_SHAPE = (BATCH_SIZE, 1, MAP_SHAPE[0], MAP_SHAPE[1])\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP=''\n",
    "\n",
    "CONFIG = dict(\n",
    "    dataset = DATASET,\n",
    "    subset = SUBSET,\n",
    "\n",
    "    layers_crit = NUM_LAYERS_CRIT,\n",
    "    kernels_crit = KERNEL_CRIT,\n",
    "    stride_crit = STRIDE_CRIT,\n",
    "    padding_crit = PAD_CRIT,\n",
    "    features_crit = FEATURES_CRIT,\n",
    "\n",
    "    layers_gen = NUM_LAYERS_GEN,\n",
    "    kernels_gen = KERNEL_GEN,\n",
    "    stride_gen = STRIDE_GEN,\n",
    "    padding_gen = PAD_GEN,\n",
    "    features_gen = FEATURES_GEN,\n",
    "\n",
    "    batch_size = BATCH_SIZE,\n",
    "    learning_rate_crit = LR_CRIT,\n",
    "    learning_rate_gen = LR_GEN,\n",
    "    crit_iterations = CRIT_ITERATIONS,\n",
    "    gp_coefficient = LAMBDA\n",
    ")\n",
    "\n",
    "if RECORD_METRICS:\n",
    "    run = wandb.init(project='wgan-gp', entity='aicv-lab', config=CONFIG, group=GROUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define The GAN's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the GAN's definitions\n",
    "if RECORD_METRICS:\n",
    "    savepath = os.path.join(os.getcwd(), 'checkpoints', run.name)\n",
    "    if not os.path.isdir(savepath):\n",
    "        os.makedirs(savepath)\n",
    "    shutil.copy(f'./GAN.py', os.path.join(savepath, 'GAN.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(coeff, critic, real, fake, device=\"cpu\"):\n",
    "    # sample x_hat from P(x_hat)\n",
    "    rand = torch.randn((real.shape[0], 1, 1, 1), device=device) # generate a random number from 0 to 1 for each matrix in the batch\n",
    "    x_hat = rand*real + (1-rand)*fake\n",
    "\n",
    "    critic_output = critic(x_hat)\n",
    "    grad_ones = torch.ones_like(critic_output, device=device)\n",
    "\n",
    "    gp = torch.autograd.grad(                                   # find magnitude of critic's resulting gradient\n",
    "        inputs = x_hat,\n",
    "        outputs = critic_output,\n",
    "        grad_outputs = grad_ones,\n",
    "        create_graph = True,\n",
    "        retain_graph = True\n",
    "    )[0]\n",
    "\n",
    "    gp = torch.norm(gp, p=2, dim=(1,2,3))    # vector norm of each gradient\n",
    "    gp = (gp - 1)**2\n",
    "    gp = coeff * torch.mean(gp)\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to override __init__, __len__, __getitem__\n",
    "# as per datasets requirement\n",
    "class PathsDataset(torch.utils.data.Dataset):\n",
    "    # init the dataset, shape = L x W\n",
    "    def __init__(self, inputs_dir, dataset, subset, device='cpu'):\n",
    "        self.paths = [] # create a list to hold all paths read from\n",
    "        \n",
    "        load_dir = os.getcwd()\n",
    "        load_dir = os.path.join(load_dir, inputs_dir, dataset, subset, 'paths')\n",
    "        if not os.path.isdir(load_dir):\n",
    "            print(f\"ERROR: The path directory {load_dir} does not exist\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        path_files = os.scandir(load_dir)\n",
    "        for item in path_files:\n",
    "            self.paths.append(torch.load(os.path.join(load_dir, item)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.paths[idx]\n",
    "        x = x.to(device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PathsDataset(INPUT_DIR, DATASET, SUBSET, device=device)\n",
    "dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_epoch = START_EPOCH\n",
    "\n",
    "gen = Generator(FEATURES_GEN, KERNEL_GEN, STRIDE_GEN, PAD_GEN, device=device)\n",
    "critic = Critic(FEATURES_CRIT, KERNEL_CRIT, STRIDE_CRIT, PAD_CRIT, device=device)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LR_GEN, betas = (0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LR_CRIT, betas = (0.0, 0.9))\n",
    "\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_noise = torch.randn(NOISE_SHAPE, device=device).abs()\n",
    "\n",
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    curr_epoch += 1\n",
    "    for batch_idx, real in enumerate(dataloader):\n",
    "        # real = real.to(device)\n",
    "\n",
    "        initial_path = real[:,1:2,:,:]\n",
    "        # fixed_input = torch.concat((fixed_noise, real[:,1:,:,:]), axis=1)\n",
    "        fixed_input = real[:,1:,:,:]\n",
    "\n",
    "        for _ in range(CRIT_ITERATIONS):\n",
    "            # TODO: try without abs()\n",
    "            # noise = torch.randn_like(real[:,-1:,:,:], device=device).abs()\n",
    "            # noise = torch.concat((noise, real[:,1:,:,:]), axis=1)\n",
    "            noise = real[:,1:,:,:]\n",
    "\n",
    "            fake = gen(noise)\n",
    "            fake = torch.concat((fake, real[:,1:,:,:]), axis=1)\n",
    "\n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake)\n",
    "            gp = gradient_penalty(LAMBDA, critic, real, fake, device=device) # compute the gradient penalty\n",
    "            loss_critic = (\n",
    "                torch.mean(critic_fake) - torch.mean(critic_real) + gp\n",
    "            )\n",
    "\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "        ### Training generator: min E(critic(gen_fake))\n",
    "        output = critic(fake)\n",
    "        loss_gen = -torch.mean(output)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{curr_epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \" +\n",
    "                  f\"Loss D: {loss_critic:.4f}, Lambda GP: {gp:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            if RECORD_METRICS:\n",
    "                savepath = os.path.join(os.getcwd(), 'checkpoints', run.name, 'gen')\n",
    "                if not os.path.isdir(savepath):\n",
    "                    os.makedirs(savepath)\n",
    "                torch.save({\n",
    "                            'dataset': DATASET,\n",
    "                            'config': CONFIG,\n",
    "                            'state': gen.state_dict()\n",
    "                            },\n",
    "                            os.path.join(savepath, f'step_{run.step}.tar'))\n",
    "\n",
    "                # save critic checkpoint\n",
    "                savepath = os.path.join(os.getcwd(), 'checkpoints', run.name, 'crit')\n",
    "                if not os.path.isdir(savepath):\n",
    "                    os.makedirs(savepath)\n",
    "                torch.save({\n",
    "                            'dataset': DATASET,\n",
    "                            'config': CONFIG,\n",
    "                            'state': critic.state_dict()\n",
    "                            },\n",
    "                            os.path.join(savepath, f'step_{run.step}.tar'))\n",
    "\n",
    "            if BATCH_SIZE > 8:\n",
    "                outputs = gen(fixed_input[:8,:,:,:])\n",
    "                inputs = real[:8,:,:,:]\n",
    "                # outputs = torch.concat((outputs, fixed_input[:8,1:,:,:]), axis=1)\n",
    "                outputs = torch.concat((outputs, fixed_input[:8,:,:,:]), axis=1)\n",
    "            else:\n",
    "                outputs = gen(fixed_input)\n",
    "                inputs = real\n",
    "                # outputs = torch.concat((outputs, fixed_input[:,1:,:,:]), axis=1)\n",
    "                outputs = torch.concat((outputs, fixed_input[:,:,:,:]), axis=1)\n",
    "\n",
    "            if RECORD_METRICS:\n",
    "                wandb.log({\n",
    "                    'epoch': curr_epoch,\n",
    "                    'generator loss': loss_gen,\n",
    "                    'critic loss': loss_critic,\n",
    "                    'gradient penalty': gp,\n",
    "                    'fake': wandb.Image(outputs),\n",
    "                    'real': wandb.Image(inputs)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECORD_METRICS:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

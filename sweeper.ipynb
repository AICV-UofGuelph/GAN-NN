{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Code adapted from: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/ac5dcd03a40a08a8af7e1a67ade37f28cf88db43/ML/Pytorch/GANs/2.%20DCGAN/train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.tensorboard.summary import hparams\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tfms\n",
    "\n",
    "import os, shutil\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_NAME = 'map_64x64'\n",
    "MAP_DIMS = (64,64)\n",
    "MAX_DATA_POINTS = 100\n",
    "DATA_DIR = \"./logs/\"                     # name of directory that TensorBoard data is saved in\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparams for sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    features_gen = [32, 64, 128],\n",
    "    features_disc = [32, 64, 128],\n",
    "    noise_channels = [32, 64],\n",
    "    lr_gen = [1e-3, 1e-4, 1e-5],\n",
    "    lr_disc = [1e-6, 1e-7, 1e-8],\n",
    "    batch_size = [10, 50],\n",
    "    num_epochs = [25]\n",
    ")\n",
    "param_values = [v for v in parameters.values()]\n",
    "total_param_runs = np.prod([len(v) for v in parameters.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tfms.Compose(\n",
    "    [\n",
    "        tfms.ToTensor(),\n",
    "        tfms.Normalize([0.5 for _ in range(1)], [0.5 for _ in range(1)])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, features, device='cpu'):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, features, kernel_size=4, stride=2, padding=1, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features * 2, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 2, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(features * 2, features * 4, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 4, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(features * 4, features * 8, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 8, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, 1, kernel_size=4, stride=2, padding=0, device=device), # convert to single channel\n",
    "            nn.AdaptiveAvgPool2d(1),    # pool the matrix into a single value for sigmoid\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "        y = self.block5(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_channels, features, device='cpu'):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_channels, features * 16, kernel_size=4, stride=1, padding=0, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 16, features * 8, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 8, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 8, features * 4, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 4, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 4, features * 2, kernel_size=4, stride=2, padding=1, bias=False, device=device),\n",
    "            nn.BatchNorm2d(features * 2, device=device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 2, 1, kernel_size=4, stride=2, padding=1, device=device),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "        y = self.block5(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_dims(map_dims):\n",
    "    # For each convtranspose layer:\n",
    "    # dim = round(math.ceil((dim + (2*padding) - kernel_size) / stride)) + 1\n",
    "    # The output will need to be trimmed down to the desired size (This may hurt generalizability)\n",
    "    shape = map_dims\n",
    "\n",
    "    shape = round(math.ceil((shape + (2*1) - 4) / 2)) + 1  # Layer 5\n",
    "    shape = round(math.ceil((shape + (2*1) - 4) / 2)) + 1  # Layer 4\n",
    "    shape = round(math.ceil((shape + (2*1) - 4) / 2)) + 1  # Layer 3\n",
    "    shape = round(math.ceil((shape + (2*1) - 4) / 2)) + 1  # Layer 2\n",
    "    shape = round(math.ceil((shape + (2*0) - 4) / 2)) + 1  # Layer 1\n",
    "\n",
    "    return shape\n",
    "\n",
    "def trim(path, map_dims):\n",
    "    resize = path.shape - map_dims\n",
    "\n",
    "    axis_trim = (resize[0]//2, path.shape[0] - (resize[0]//2 + resize[0]%2))\n",
    "    path = path[axis_trim[0]:axis_trim[1], :]\n",
    "\n",
    "    axis_trim = (resize[1]//2, path.shape[1] - (resize[1]//2 + resize[1]%2))\n",
    "    path = path[:, axis_trim[0]:axis_trim[1]]\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefining add_hparams() function in SummaryWriter class so that hyperparams are saved in a neater way\n",
    "# code from https://github.com/pytorch/pytorch/issues/32651\n",
    "class SummaryWriter(SummaryWriter):\n",
    "    def add_hparams(self, hparam_dict, metric_dict):\n",
    "        torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n",
    "        if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n",
    "            raise TypeError('hparam_dict and metric_dict should be dictionary.')\n",
    "        exp, ssi, sei = hparams(hparam_dict, metric_dict)\n",
    "\n",
    "        logdir = self._get_file_writer().get_logdir()\n",
    "        \n",
    "        with SummaryWriter(log_dir=logdir) as w_hp:\n",
    "            w_hp.file_writer.add_summary(exp)\n",
    "            w_hp.file_writer.add_summary(ssi)\n",
    "            w_hp.file_writer.add_summary(sei)\n",
    "            for k, v in metric_dict.items():\n",
    "                w_hp.add_scalar(k, v)\n",
    "\n",
    "class PathsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, transform=None, shape = (100,100)):\n",
    "        self.paths = [] # create a list to hold all paths read from file\n",
    "        for filename in os.listdir(path):\n",
    "            with open(os.path.join(path, filename), 'r') as f: # open in readonly mode\n",
    "                self.flat_path = np.loadtxt(f) # load in the flat path from file\n",
    "                self.path = np.asarray(self.flat_path, dtype=int).reshape(len(self.flat_path)//2,2) #unflatten the path from the file\n",
    "\n",
    "                self.path_matrix = self.convert_path(shape, self.path)\n",
    "                \n",
    "                self.paths.append(self.path_matrix) # add the path to paths list\n",
    "        self.transform = transform\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def convert_path(self, map_dim, path):\n",
    "        path_mat = np.zeros(map_dim, dtype=float)\n",
    "\n",
    "        # Make the path continuous\n",
    "        for i in range(path.shape[0] - 1):\n",
    "            x = path[i,0]\n",
    "            x1 = path[i,0]\n",
    "            x2 = path[i+1,0]\n",
    "\n",
    "            y = path[i,1]\n",
    "            y1 = path[i,1]\n",
    "            y2 = path[i+1,1]\n",
    "\n",
    "            if (x1 < x2):\n",
    "                x_dir = 1\n",
    "            else:\n",
    "                x_dir = -1\n",
    "\n",
    "            if (y1 < y2):\n",
    "                y_dir = 1\n",
    "            else:\n",
    "                y_dir = -1\n",
    "\n",
    "            # Determine y from x\n",
    "            if x2-x1 != 0:\n",
    "                m = (y2-y1)/(x2-x1)\n",
    "                while x != x2:\n",
    "                    y = round(m*(x-x1) + y1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    x += x_dir\n",
    "            else:\n",
    "                while x != x2:\n",
    "                    path_mat[y1,x] = 1\n",
    "                    x += x_dir\n",
    "\n",
    "\n",
    "            x = path[i,0]\n",
    "            x1 = path[i,0]\n",
    "            x2 = path[i+1,0]\n",
    "\n",
    "            y = path[i,1]\n",
    "            y1 = path[i,1]\n",
    "            y2 = path[i+1,1]\n",
    "\n",
    "            # Determine x from y\n",
    "            if y2-y1 != 0:\n",
    "                m = (x2-x1)/(y2-y1)\n",
    "                while y != y2:\n",
    "                    x = round(m*(y-y1) + x1)\n",
    "                    path_mat[y,x] = 1\n",
    "                    y += y_dir\n",
    "            else:\n",
    "                while y != y2:\n",
    "                    path_mat[y,x1] = 1\n",
    "                    y += y_dir\n",
    "            \n",
    "        path_mat[path[path.shape[0]-1,1], path[path.shape[0]-1,0]] = 1     # Include the last point in the path\n",
    "\n",
    "        return path_mat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.float32(self.paths[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x).cuda()\n",
    "            \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PathsDataset(path=f'./env/{MAP_NAME}/paths/', shape=MAP_DIMS, transform=transforms)\n",
    "# dataset = PathsDataset(path=f'./data/{MAP_NAME}/', shape=MAP_DIMS, transform=transforms)\n",
    "\n",
    "NOISE_DIMS = noise_dims(MAP_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset data folder:\n",
    "if os.path.isdir(DATA_DIR):\n",
    "    shutil.rmtree(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = 0\n",
    "\n",
    "for (features_gen, features_disc, noise_channels, lr_gen, lr_disc, batch_size, num_epochs) in product(*param_values):\n",
    "\n",
    "    writer = SummaryWriter(f\"{DATA_DIR}run{run_number}\")\n",
    "\n",
    "    disc = Discriminator(features_disc, device=DEVICE)\n",
    "    gen = Generator(noise_channels, features_gen, device=DEVICE)\n",
    "    fixed_noise = torch.randn((batch_size, noise_channels, NOISE_DIMS[0], NOISE_DIMS[1]), device=DEVICE)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    opt_disc = optim.Adam(disc.parameters(), lr=lr_disc)\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=lr_gen)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    loss_step_rate = round((len(loader)*num_epochs)/MAX_DATA_POINTS)\n",
    "\n",
    "    step = 0\n",
    "    loss_step = 0\n",
    "    img_step = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, real in enumerate(loader):\n",
    "            batch_size = real.shape[0]\n",
    "\n",
    "            ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "            noise = torch.randn((batch_size, noise_channels, NOISE_DIMS[0], NOISE_DIMS[1]), device=DEVICE)\n",
    "            fake = gen(noise)\n",
    "            disc_real = disc(real)\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake)\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "            ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "            # where the second option of maximizing doesn't suffer from\n",
    "            # saturating gradients\n",
    "            output = disc(fake)\n",
    "            lossG = criterion(output, torch.ones_like(output))\n",
    "            gen.zero_grad()\n",
    "            lossG.backward()\n",
    "            opt_gen.step()\n",
    "\n",
    "            if step % loss_step_rate == 0:              # save loss values at pre-determined rate\n",
    "                # saving loss\n",
    "                writer.add_scalar(f\"Discriminator Loss\", lossD, loss_step)\n",
    "                writer.add_scalar(f\"Generator Loss\", lossG, loss_step)\n",
    "                loss_step += 1\n",
    "\n",
    "                print(\n",
    "                    f\"Run [{run_number+1}/{total_param_runs}] Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx}/{len(loader)}] \\\n",
    "                        Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "                )\n",
    "\n",
    "            if batch_idx == len(loader)-1:              # save an image at the end of every epoch\n",
    "                with torch.no_grad():\n",
    "                    fake = gen(fixed_noise)\n",
    "                    img_grid_fake = torchvision.utils.make_grid(\n",
    "                        fake[:batch_size], normalize=True\n",
    "                    )\n",
    "                    img_grid_real = torchvision.utils.make_grid(\n",
    "                        real[:batch_size], normalize=True\n",
    "                    )\n",
    "\n",
    "                    # saving output\n",
    "                    writer.add_image(\n",
    "                        f\"Generator Output\", img_grid_fake, global_step=img_step\n",
    "                    )\n",
    "                    writer.add_image(\n",
    "                        f\"Path Data\", img_grid_real, global_step=img_step\n",
    "                    )\n",
    "                img_step += 1\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    #saving hyperparams:\n",
    "    writer.add_hparams({\"gen_features\": features_gen, \"disc_features\": features_disc, \"noise_channels\": noise_channels, \"gen_lr\": lr_gen, \"disc_lr\": lr_disc, \"batch_size\": batch_size, \"epochs\": num_epochs}, {\"gen loss\": lossG})\n",
    "    writer.close()\n",
    "    run_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

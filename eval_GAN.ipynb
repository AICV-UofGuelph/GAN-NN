{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import create_paths\n",
    "from create_paths import smoothen_paths\n",
    "# from create_paths import mat_to_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib.util\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the evaluation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "DATA_DIR = 'inputs' # the root directory containing the processed input data\n",
    "DATASET = 'random_points_1'      # (String) The name of the dataset to load. Leave as None to use the same dataset that the model was trained on.\n",
    "SUBSET = 'eval'     # The name of the subset to load from\n",
    "\n",
    "RUN_NAME = 'gentle-smoke-106'\n",
    "STEP = 23\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "SMOOTH_VAL = 10\n",
    "\n",
    "NUM_SAMPLES = 5     # the number of example outputs to generate\n",
    "FIG_SCALE = 20      # the number of pixels per inch in the generated plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the gan's class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the cell only runs once\n",
    "try:\n",
    "    if MODEL_IMPORTED:\n",
    "        print(\"Skipping cell\")\n",
    "except:\n",
    "    model_path = os.path.join(os.getcwd(), 'checkpoints', RUN_NAME, 'GAN.py')\n",
    "    if not os.path.isfile(model_path):\n",
    "        print(f\"ERROR: The model's class definitions are not saved at {model_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # From https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n",
    "    spec = importlib.util.spec_from_file_location('GAN', model_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules['GAN'] = module\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "MODEL_IMPORTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(path, map_dim):\n",
    "    path_mat = torch.zeros(map_dim)\n",
    "\n",
    "    # Make the path continuous\n",
    "    for i in range(path.shape[0] - 1):\n",
    "        x = int(path[i,1])\n",
    "        x1 = int(path[i,1])\n",
    "        x2 = int(path[i+1,1])\n",
    "\n",
    "        y = int(path[i,0])\n",
    "        y1 = int(path[i,0])\n",
    "        y2 = int(path[i+1,0])\n",
    "\n",
    "        if (x1 < x2):\n",
    "            x_dir = 1\n",
    "        else:\n",
    "            x_dir = -1\n",
    "\n",
    "        if (y1 < y2):\n",
    "            y_dir = 1\n",
    "        else:\n",
    "            y_dir = -1\n",
    "\n",
    "        # Determine y from x\n",
    "        if x2-x1 != 0:\n",
    "            m = (y2-y1)/(x2-x1)\n",
    "            while x != x2:\n",
    "                y = round(m*(x-x1) + y1)\n",
    "                path_mat[y,x] = 1\n",
    "                x += x_dir\n",
    "        else:\n",
    "            while x != x2:\n",
    "                path_mat[y1,x] = 1\n",
    "                x += x_dir\n",
    "\n",
    "\n",
    "        x = int(path[i,1])\n",
    "        x1 = int(path[i,1])\n",
    "        x2 = int(path[i+1,1])\n",
    "\n",
    "        y = int(path[i,0])\n",
    "        y1 = int(path[i,0])\n",
    "        y2 = int(path[i+1,0])\n",
    "\n",
    "        # Determine x from y\n",
    "        if y2-y1 != 0:\n",
    "            m = (x2-x1)/(y2-y1)\n",
    "            while y != y2:\n",
    "                x = round(m*(y-y1) + x1)\n",
    "                path_mat[y,x] = 1\n",
    "                y += y_dir\n",
    "        else:\n",
    "            while y != y2:\n",
    "                path_mat[y,x1] = 1\n",
    "                y += y_dir\n",
    "        \n",
    "    path_mat[int(path[path.shape[0]-1,0]), int(path[path.shape[0]-1,1])] = 1     # Include the last point in the path\n",
    "\n",
    "    return torch.tensor(path_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the network(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the cell only runs once\n",
    "try:\n",
    "    if MODEL_LOADED:\n",
    "        print(\"Skipping cell execution\")\n",
    "except:\n",
    "\n",
    "    from GAN import Generator\n",
    "\n",
    "    model = torch.load(f'checkpoints/{RUN_NAME}/gen/step_{STEP}.tar')\n",
    "\n",
    "    config = model['config']\n",
    "    gen = Generator(config['features_gen'], config['kernels_gen'], config['stride_gen'], config['padding_gen'], device=DEVICE)\n",
    "\n",
    "    gen.load_state_dict(model['state'])\n",
    "    if DATASET == None:\n",
    "        DATASET = model['dataset']\n",
    "MODEL_LOADED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the input set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the cell only runs once\n",
    "try:\n",
    "    if INPUT_LOADED:\n",
    "        print(\"Skipping cell execution\")\n",
    "except:\n",
    "\n",
    "    # Make sure inputs exist for the desired dataset\n",
    "    input_dir = os.path.join(os.getcwd(), DATA_DIR, DATASET, SUBSET, 'paths')\n",
    "    map_dir = os.path.join(os.getcwd(), DATA_DIR, DATASET, SUBSET, 'maps')\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f'ERROR: {input_dir} is not a valid directory')\n",
    "        sys.exit(1)\n",
    "    if not os.path.isdir(map_dir):\n",
    "        print(f'ERROR: {map_dir} is not a valid directory')\n",
    "        sys.exit(2)\n",
    "\n",
    "    # Load all inputs\n",
    "    inputs = []\n",
    "    maps = []\n",
    "    truth = os.scandir(input_dir)\n",
    "    for item in truth:\n",
    "        maps.append(np.asarray(torch.load(os.path.join(map_dir, item.name))))\n",
    "        true_item = torch.load(os.path.join(input_dir, item))\n",
    "        inputs.append(true_item)\n",
    "\n",
    "    dataloader = DataLoader(inputs, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "\n",
    "INPUT_LOADED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the resulting outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.Tensor()\n",
    "for item_idx, item in enumerate(dataloader):\n",
    "    item = item.to(DEVICE)\n",
    "\n",
    "    # Generate some fake paths\n",
    "    # noise = torch.rand_like(item[:,0:1,:,:])\n",
    "    # noise = torch.cat((noise, item[:,1:,:,:]), axis=1)\n",
    "    noise = item[:,1:,:,:]\n",
    "    fake = gen(noise)\n",
    "\n",
    "    out = torch.flip(item, [1])     # map, endpoints, truth\n",
    "    out = torch.cat((out, fake), axis=1)  # map, endpoints, truth, generated (raw)\n",
    "\n",
    "    out = out.to('cpu')\n",
    "    outputs = torch.cat((outputs, out), axis=0)\n",
    "    if item_idx == NUM_SAMPLES:\n",
    "        break\n",
    "\n",
    "# Channels: map, endpoints, ground truth, generated (raw)\n",
    "outputs = outputs[:NUM_SAMPLES,:,:,:]\n",
    "maps = maps[:NUM_SAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "round outputs using Rachael's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each item, find start/end points using direct path (where direct path == 2)\n",
    "# outputs = torch.tensor(outputs)\n",
    "smooth = torch.zeros_like(outputs[:,-1:,:,:])\n",
    "for i in range(outputs.shape[0]):\n",
    "    # Find start/end\n",
    "    ends = torch.nonzero(outputs[i,1,:,:] > 1)\n",
    "    # ends = torch.flip(ends, [0])\n",
    "\n",
    "    smooth[i] = path_to_tensor(smoothen_paths(outputs[i,-1:,:,:], ends[0], ends[1], smooth_val=SMOOTH_VAL, display=False)[0], outputs[i,-1,:,:].shape)[None,None,:,:]\n",
    "\n",
    "\n",
    "outputs = torch.cat((outputs, smooth), axis=1)\n",
    "\n",
    "# Channels: map, endpoints, ground truth, generated (raw), generated (smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format and save input, raw output, and rounded path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.asarray(outputs)\n",
    "\n",
    "fig = plt.figure(figsize=(max(4, 4*outputs[0,0,:,:].shape[1]/FIG_SCALE),max(NUM_SAMPLES*(outputs[0,0,:,:].shape[1]/outputs[0,0,:,:].shape[0]), NUM_SAMPLES*outputs[0,0,:,:].shape[0]/FIG_SCALE)))\n",
    "\n",
    "col_title = True\n",
    "for i in range(NUM_SAMPLES):\n",
    "\n",
    "    endpoints = np.squeeze(np.nonzero(outputs[i,1,:,:] == 2))\n",
    "\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,5,i*5+1)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(maps[i])\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Obstacles')\n",
    "\n",
    "    # TODO: remove endpoints column, plot endpoints on other subplots\n",
    "    # sub = fig.add_subplot(NUM_SAMPLES,5,i*5+2)\n",
    "    # sub.set_xticks([])\n",
    "    # sub.set_yticks([])\n",
    "    # plt.imshow(np.stack((outputs[i,1,:,:], np.zeros_like(outputs[i,1,:,:]), maps[i]), axis=-1))\n",
    "    # if col_title:\n",
    "    #     plt.title('Endpoints')\n",
    "\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,4,i*4+2)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(np.stack((outputs[i,2,:,:], np.zeros_like(outputs[i,2,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Truth')\n",
    "\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,4,i*4+3)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(np.stack((outputs[i,3,:,:], np.zeros_like(outputs[i,3,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Generated')\n",
    "\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,4,i*4+4)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(np.stack((outputs[i,-1,:,:], np.zeros_like(outputs[i,4,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Smoothened')\n",
    "\n",
    "    col_title = False\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

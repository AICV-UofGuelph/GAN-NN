{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from path_functions import smoothen_paths, check_if_avoids_obstacles\n",
    "# from create_paths import mat_to_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "import data_manager as dm\n",
    "\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the evaluation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_grad_enabled(False)\n",
    "GAN_TYPE = \"AutoEncoder\"   # The type of GAN being evaluated (See README.md for gan types, e.g. \"AutoEncoder\", \"Pix2Pix\")\n",
    "\n",
    "# Checkpoint saving directory\n",
    "# loc = os.getcwd()\n",
    "loc = '/data'\n",
    "\n",
    "DATASET = 'random_20_density'      # (String) The name of the dataset to load. Leave as None to use the same dataset that the model was trained on.\n",
    "SUBSET = 'eval'     # The name of the subset to load from\n",
    "\n",
    "RUN_NAME = 'fiery-glade-181'\n",
    "STEP = 479\n",
    "\n",
    "BATCH_SIZE = 1  # Must be 1 in order to get accurate estimation of prediction times\n",
    "SMOOTH_VAL = 1\n",
    "\n",
    "NUM_SAMPLES = 80     # the number of example outputs to generate\n",
    "FIG_SCALE = 20      # the number of pixels per inch in the generated plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the gan's class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the cell only runs once\n",
    "try:\n",
    "    if MODEL_IMPORTED:\n",
    "        print(\"Skipping cell\")\n",
    "except:\n",
    "    config = dm.load_gan(RUN_NAME)\n",
    "\n",
    "    from GANdefs import Generator\n",
    "    gen = Generator(config['features_gen'], config['kernels_gen'], config['stride_gen'], config['padding_gen'], device=DEVICE)\n",
    "\n",
    "    if DATASET == None:\n",
    "        DATASET = config['dataset']\n",
    "        SUBSET = config['subset']\n",
    "\n",
    "MODEL_IMPORTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(path, map_dim):\n",
    "    path_mat = torch.zeros(map_dim)\n",
    "\n",
    "    # Make the path continuous\n",
    "    for i in range(path.shape[0] - 1):\n",
    "        x = int(path[i,1])\n",
    "        x1 = int(path[i,1])\n",
    "        x2 = int(path[i+1,1])\n",
    "\n",
    "        y = int(path[i,0])\n",
    "        y1 = int(path[i,0])\n",
    "        y2 = int(path[i+1,0])\n",
    "\n",
    "        if (x1 < x2):\n",
    "            x_dir = 1\n",
    "        else:\n",
    "            x_dir = -1\n",
    "\n",
    "        if (y1 < y2):\n",
    "            y_dir = 1\n",
    "        else:\n",
    "            y_dir = -1\n",
    "\n",
    "        # Determine y from x\n",
    "        if x2-x1 != 0:\n",
    "            m = (y2-y1)/(x2-x1)\n",
    "            while x != x2:\n",
    "                y = round(m*(x-x1) + y1)\n",
    "                path_mat[y,x] = 1\n",
    "                x += x_dir\n",
    "        else:\n",
    "            while x != x2:\n",
    "                path_mat[y1,x] = 1\n",
    "                x += x_dir\n",
    "\n",
    "\n",
    "        x = int(path[i,1])\n",
    "        x1 = int(path[i,1])\n",
    "        x2 = int(path[i+1,1])\n",
    "\n",
    "        y = int(path[i,0])\n",
    "        y1 = int(path[i,0])\n",
    "        y2 = int(path[i+1,0])\n",
    "\n",
    "        # Determine x from y\n",
    "        if y2-y1 != 0:\n",
    "            m = (x2-x1)/(y2-y1)\n",
    "            while y != y2:\n",
    "                x = round(m*(y-y1) + x1)\n",
    "                path_mat[y,x] = 1\n",
    "                y += y_dir\n",
    "        else:\n",
    "            while y != y2:\n",
    "                path_mat[y,x1] = 1\n",
    "                y += y_dir\n",
    "        \n",
    "    path_mat[int(path[path.shape[0]-1,0]), int(path[path.shape[0]-1,1])] = 1     # Include the last point in the path\n",
    "\n",
    "    return torch.tensor(path_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the network(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the cell only runs once\n",
    "try:\n",
    "    if MODEL_LOADED:\n",
    "        print(\"Skipping cell execution\")\n",
    "except:\n",
    "\n",
    "    state = dm.load_checkpoint(RUN_NAME, STEP, loc)\n",
    "    gen.load_state_dict(state['gen'])\n",
    "\n",
    "MODEL_LOADED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the input set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to override __init__, __len__, __getitem__\n",
    "# as per datasets requirement\n",
    "class PathsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, subset, device='cpu'):\n",
    "        self.device = device\n",
    "        self.paths = dm.load_input(dataset, subset) # Load all of the paths in the specified set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.paths[idx]\n",
    "        x = x.to(self.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the cell only runs once\n",
    "try:\n",
    "    if INPUT_LOADED:\n",
    "        print(\"Skipping cell execution\")\n",
    "except:\n",
    "\n",
    "    inputs = dm.load_input(DATASET, SUBSET) # load input gives us a tensor with 3 channels: real path, end points, SDF maps (in that order) \n",
    "    dataloader = DataLoader(inputs, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "\n",
    "INPUT_LOADED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the resulting outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_time = datetime(1,1,1,0,0)\n",
    "start = time.time()\n",
    "outputs = torch.Tensor()\n",
    "for item_idx, item in enumerate(dataloader):\n",
    "    item = item.to(DEVICE)\n",
    "\n",
    "    # Generate some fake paths\n",
    "    if GAN_TYPE == \"AutoEncoder\":\n",
    "        noise = torch.rand_like(item[:,0:1,:,:])    # random noise matrix with same dimensions of the map (Note: may want try different noise distributions)\n",
    "        noise = torch.cat((noise, item[:,1:,:,:]), axis=1)  # adding noise, then endpoints/line, then map to noise. (1: gives us all channels except truth/RRT* path)\n",
    "    elif GAN_TYPE == \"Pix2Pix\":\n",
    "        item = F.interpolate(item, size=(256,256))\n",
    "        noise = item[:,1:,:,:]  # endpoints, map\n",
    "    else:\n",
    "        print(f\"ERROR: '{GAN_TYPE}' is not a valid type of GAN\")\n",
    "        exit()\n",
    "\n",
    "    t = datetime.now()\n",
    "    fake = gen(noise)\n",
    "    pred_time += datetime.now() - t\n",
    "\n",
    "    out = torch.flip(item, [1])     # map, endpoints, truth\n",
    "    out = torch.cat((out, fake[:,:1,:,:]), axis=1)  # map, endpoints, truth, generated (raw)\n",
    "\n",
    "    out = out.to('cpu')\n",
    "    outputs = torch.cat((outputs, out), axis=0)     # append the batch to the array of outputs\n",
    "    if item_idx == NUM_SAMPLES:\n",
    "        break\n",
    "\n",
    "# Channels: map, endpoints, ground truth, generated (raw)\n",
    "outputs = outputs[:NUM_SAMPLES,:,:,:]   # how many we want to display (from 0 to NUM_SAMPLES-1)\n",
    "maps = outputs[:NUM_SAMPLES,:1,:,:]\n",
    "maps = np.squeeze(maps)\n",
    "maps[maps > 0] = 0  # converting from SDF to actual map so we can see if paths collide with obstacles\n",
    "maps[maps < 0] = 1\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(delta)\n",
    "print(NUM_SAMPLES)\n",
    "print(f\"took average {delta/NUM_SAMPLES} seconds per prediction\")\n",
    "\n",
    "avg_ms = pred_time.microsecond // NUM_SAMPLES\n",
    "print(f\"Average Computation Time: {avg_ms:d} ms\")   # may encounter issue where avg time not represented correctly if total time >= 1s (could happen when NUM_SAMPLES is too large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "round outputs using Rachael's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each item, find start/end points using direct path (where direct path == 2)\n",
    "# outputs = torch.tensor(outputs)\n",
    "smooth = torch.zeros_like(outputs[:,-1:,:,:])\n",
    "for i in range(outputs.shape[0]):\n",
    "    # Find start/end\n",
    "    ends = torch.nonzero(outputs[i,1,:,:] > 1)\n",
    "    # ends = torch.flip(ends, [0])\n",
    "\n",
    "    smooth[i] = path_to_tensor(smoothen_paths(outputs[i,-1:,:,:], ends[0], ends[1], smooth_val=SMOOTH_VAL, display=False)[0], outputs[i,-1,:,:].shape)[None,None,:,:]\n",
    "\n",
    "\n",
    "outputs = torch.cat((outputs, smooth), axis=1)\n",
    "\n",
    "# Channels: map, endpoints, ground truth, generated (raw), generated (smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format and save input, raw output, and rounded path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "outputs = np.asarray(outputs)\n",
    "\n",
    "fig = plt.figure(figsize=(max(4, 4*outputs[0,0,:,:].shape[1]/FIG_SCALE),max(NUM_SAMPLES*(outputs[0,0,:,:].shape[1]/outputs[0,0,:,:].shape[0]), NUM_SAMPLES*outputs[0,0,:,:].shape[0]/FIG_SCALE)))\n",
    "\n",
    "col_title = True\n",
    "\n",
    "gan_total_length = 0 # variable to hold the total length of all LSTM generated paths\n",
    "rrt_star_total_length = 0 # variable to hold the total length of all rrt* generated paths\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    gan_this_length = 0 # variable to hold length of this LSTM generated path\n",
    "    rrt_star_this_length = 0 # variable to hold length of this rrt* generated path\n",
    "\n",
    "    endpoints = np.squeeze(np.nonzero(outputs[i,1,:,:] == 2))\n",
    "\n",
    "    # Show map\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,5,i*5+1)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(maps[i])\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Obstacles')\n",
    "\n",
    "    # show real path\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,4,i*4+2)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(np.stack((outputs[i,2,:,:], np.zeros_like(outputs[i,2,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Truth')\n",
    "    # measure the distance of the RRT* training path\n",
    "    rrt_star_xs = np.where(outputs[i,2,:,:]==1)[0]\n",
    "    rrt_star_ys = np.where(outputs[i,2,:,:]==1)[1]\n",
    "    path_len = len(rrt_star_xs)\n",
    "    print(f\"Path length: {path_len}\")\n",
    "    for itr in range (1,path_len):\n",
    "        rrt_star_this_length = rrt_star_this_length + distance.euclidean((rrt_star_xs[itr], rrt_star_ys[itr]),(rrt_star_xs[itr-1], rrt_star_ys[itr-1]))\n",
    "    print(f\"distance of this RRT* path: {rrt_star_this_length}\")\n",
    "    rrt_star_total_length += rrt_star_this_length # incrament total path lengths (total length of all paths shown)\n",
    "\n",
    "    # show raw gan output\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,4,i*4+3)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(np.stack((outputs[i,3,:,:], np.zeros_like(outputs[i,3,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Generated')\n",
    "\n",
    "    # Show smoothened gan output\n",
    "    sub = fig.add_subplot(NUM_SAMPLES,4,i*4+4)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(np.stack((outputs[i,-1,:,:], np.zeros_like(outputs[i,4,:,:]), maps[i]), axis=-1))\n",
    "    xs = []\n",
    "    ys = []\n",
    "    f= open(f\"paths/gan_{i}.txt\",\"w+\") # open a file for writing\n",
    "    # for itr in outputs[i,4,:,:]:\n",
    "    print(f\"x: {np.where(outputs[i,4,:,:]==1)[0]}, y: {np.where(outputs[i,4,:,:]==1)[1]}\")\n",
    "    xs.append(np.where(outputs[i,4,:,:]==1)[0])\n",
    "    ys.append(np.where(outputs[i,4,:,:]==1)[1])\n",
    "    for itr in range(len(xs[0])):\n",
    "        f.write(str(xs[0][itr]))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(str(ys[0][itr]))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # measure the distance of the NDM-GAN training path\n",
    "    gan_xs = np.where(outputs[i,4,:,:]==1)[0]\n",
    "    gan_ys = np.where(outputs[i,4,:,:]==1)[1]\n",
    "    path_len = len(gan_xs)\n",
    "    print(f\"Path length: {path_len}\")\n",
    "    for itr in range (1,path_len):\n",
    "        gan_this_length = gan_this_length + distance.euclidean((gan_xs[itr], gan_ys[itr]),(gan_xs[itr-1], gan_ys[itr-1]))\n",
    "    print(f\"distance of this NDM-GAN path: {gan_this_length}\")\n",
    "    gan_total_length += gan_this_length # incrament total path lengths (total length of all paths shown)\n",
    "        \n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    if col_title:\n",
    "        plt.title('Smoothened')\n",
    "\n",
    "    col_title = False\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# calculate averge path lengths\n",
    "print(\"******\")\n",
    "print(f'Average NMD-GAJ path length: {gan_total_length/NUM_SAMPLES}')\n",
    "print(f'Average RRT* path length: {rrt_star_total_length/NUM_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f\"{loc}/GAN_figs/{RUN_NAME}/{STEP}\"#create figs directory if does not exist already\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "\n",
    "    endpoints = np.squeeze(np.nonzero(outputs[i,1,:,:] == 2))\n",
    "\n",
    "    # map_fig\n",
    "    # sub = fig.add_subplot(NUM_SAMPLES,5,i*5+1)\n",
    "    # sub.set_xticks([])\n",
    "    # sub.set_yticks([])\n",
    "    plt.figure()\n",
    "    plt.imshow(maps[i])\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    plt.savefig(f\"{loc}/GAN_figs/{RUN_NAME}/{STEP}/{i}_map.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # show real path\n",
    "    # sub = fig.add_subplot(NUM_SAMPLES,4,i*4+2)\n",
    "    # sub.set_xticks([])\n",
    "    # sub.set_yticks([])\n",
    "    # plt.imshow(np.stack((outputs[i,2,:,:], np.zeros_like(outputs[i,2,:,:]), maps[i]), axis=-1))\n",
    "    # plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    # if col_title:\n",
    "    #     plt.title('Truth')\n",
    "    plt.figure()\n",
    "    plt.imshow(np.stack((outputs[i,2,:,:], np.zeros_like(outputs[i,2,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    plt.savefig(f\"{loc}/GAN_figs/{RUN_NAME}/{STEP}/{i}_real_path.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # # show raw gan output\n",
    "    # sub = fig.add_subplot(NUM_SAMPLES,4,i*4+3)\n",
    "    # sub.set_xticks([])\n",
    "    # sub.set_yticks([])\n",
    "    # plt.imshow(np.stack((outputs[i,3,:,:], np.zeros_like(outputs[i,3,:,:]), maps[i]), axis=-1))\n",
    "    # plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    # if col_title:\n",
    "    #     plt.title('Generated')\n",
    "    plt.figure()\n",
    "    plt.imshow(np.stack((outputs[i,3,:,:], np.zeros_like(outputs[i,3,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    plt.savefig(f\"{loc}/GAN_figs/{RUN_NAME}/{STEP}/{i}_raw_gan_output.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # # Show smoothened gan output\n",
    "    # sub = fig.add_subplot(NUM_SAMPLES,4,i*4+4)\n",
    "    # sub.set_xticks([])\n",
    "    # sub.set_yticks([])\n",
    "    # plt.imshow(np.stack((outputs[i,-1,:,:], np.zeros_like(outputs[i,4,:,:]), maps[i]), axis=-1))\n",
    "    # plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    # if col_title:\n",
    "    #     plt.title('Smoothened')\n",
    "    plt.figure()\n",
    "    plt.imshow(np.stack((outputs[i,-1,:,:], np.zeros_like(outputs[i,4,:,:]), maps[i]), axis=-1))\n",
    "    plt.plot(endpoints[1,:],endpoints[0,:], 'g.')\n",
    "    plt.savefig(f\"{loc}/GAN_figs/{RUN_NAME}/{STEP}/{i}_smoothend_gan_output.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # col_title = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how frequently the generated paths are continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells contain code written by Rachael"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to code which I've written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if continuity >= 0:\n",
    "        print(f\"Predicted path continuity: {continuity:.2f}%\")\n",
    "except:\n",
    "    CALC_CONTINUITY = True\n",
    "\n",
    "    if CALC_CONTINUITY:\n",
    "        # make predictions for entire dataset\n",
    "        out = torch.Tensor()\n",
    "        continuity = 0\n",
    "        set_size = 0\n",
    "        for item_idx, item in enumerate(dataloader):\n",
    "            item = item.to(DEVICE)\n",
    "\n",
    "            # Generate some fake paths\n",
    "            if GAN_TYPE == \"AutoEncoder\":\n",
    "                noise = torch.rand_like(item[:,0:1,:,:])    # Creates random matrix with same dimensions as map\n",
    "                noise = torch.cat((noise, item[:,1:,:,:]), axis=1)  # noise, endpoints, map\n",
    "            elif GAN_TYPE == \"Pix2Pix\":\n",
    "                item = F.interpolate(item, size=(256,256)) # p2p works on 256x256 so resize what we have to this\n",
    "                noise = item[:,1:,:,:]  # endpoints, map\n",
    "            else:\n",
    "                print(f\"ERROR: '{GAN_TYPE}' is not a valid type of GAN\")\n",
    "                exit()\n",
    "            \n",
    "            fake = gen(noise)\n",
    "\n",
    "            out = torch.flip(item, [1])     # map, endpoints, truth\n",
    "            out = torch.cat((out[:,:-1,:,:], fake), axis=1)  # map, endpoints, generated (raw)\n",
    "\n",
    "            # Converts maps back to binary occupancy grids\n",
    "            maps = out[:,0,:,:]\n",
    "            maps[maps > 0] = 0\n",
    "            maps[maps < 0] = 1\n",
    "\n",
    "            out = out.to('cpu')\n",
    "            for i in range(out.shape[0]):   # go through current batch\n",
    "                # Find start/end\n",
    "                ends = torch.nonzero(out[i,1,:,:] > 1)  # getting the '2s' from the input's endpoint channel (note: see data_maneger.py>load_paths() )\n",
    "                # ends = torch.flip(ends, [0])\n",
    "\n",
    "                smooth = smoothen_paths(out[i,-1:,:,:], ends[0], ends[1], smooth_val=SMOOTH_VAL, display=False)[0]\n",
    "\n",
    "                set_size += 1\n",
    "                continuity += check_if_avoids_obstacles(smooth[:,1], smooth[:,0], maps[i,:,:])\n",
    "\n",
    "        continuity *= 100\n",
    "        continuity /= set_size\n",
    "\n",
    "        print(f\"Predicted path continuity: {continuity:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('bayesianNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65c0cf972fe55eaf0c962c4929f592d86a72c532b00283f932a90435beee88e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
